#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ™¯ç‚¹æ¨èç®—æ³•æ€§èƒ½æµ‹è¯•ç¨‹åº - ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•
å¯¹æ¯”ä¼ ç»ŸKè·¯å½’å¹¶ç®—æ³•ä¸IndexHeapä¼˜åŒ–ç®—æ³•çš„å®é™…æ‰§è¡Œæ€§èƒ½
"""

import sys
import os
import time
import random
import numpy as np
import matplotlib.pyplot as plt
import matplotlib
from collections import defaultdict
import gc
import psutil
import tracemalloc
from typing import List, Dict, Tuple
import json

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# è®¾ç½®ä¸­æ–‡å­—ä½“
matplotlib.rcParams['font.sans-serif'] = ['SimHei']
matplotlib.rcParams['axes.unicode_minus'] = False

# å¯¼å…¥é¡¹ç›®æ¨¡å—
try:
    from module.user_class import UserManager, userManager
    from module.Spot_class import spotManager
    from module.Model.Model import User
    print("âœ… æˆåŠŸå¯¼å…¥é¡¹ç›®æ¨¡å—")
except ImportError as e:
    print(f"âŒ å¯¼å…¥æ¨¡å—å¤±è´¥: {e}")
    print("è¯·ç¡®ä¿åœ¨é¡¹ç›®æ ¹ç›®å½•ä¸‹è¿è¡Œæ­¤è„šæœ¬")
    sys.exit(1)

class PerformanceProfiler:
    """æ€§èƒ½åˆ†æå™¨ï¼Œæµ‹é‡æ‰§è¡Œæ—¶é—´ã€å†…å­˜ä½¿ç”¨ç­‰æŒ‡æ ‡"""
    
    def __init__(self):
        self.reset()
    
    def reset(self):
        self.start_time = None
        self.end_time = None
        self.peak_memory = 0
        self.start_memory = 0
    
    def start_profiling(self):
        """å¼€å§‹æ€§èƒ½åˆ†æ"""
        gc.collect()  # å¼ºåˆ¶åƒåœ¾å›æ”¶
        tracemalloc.start()
        process = psutil.Process()
        self.start_memory = process.memory_info().rss / 1024 / 1024  # MB
        self.start_time = time.perf_counter()
    
    def end_profiling(self) -> Dict:
        """ç»“æŸæ€§èƒ½åˆ†æå¹¶è¿”å›ç»“æœ"""
        self.end_time = time.perf_counter()
        
        # è·å–å†…å­˜ä¿¡æ¯
        current, peak = tracemalloc.get_traced_memory()
        tracemalloc.stop()
        
        process = psutil.Process()
        end_memory = process.memory_info().rss / 1024 / 1024  # MB
        
        return {
            'execution_time': self.end_time - self.start_time,
            'peak_memory_mb': peak / 1024 / 1024,
            'memory_diff_mb': end_memory - self.start_memory,
            'start_memory_mb': self.start_memory,
            'end_memory_mb': end_memory
        }

class DirectMethodPerformanceTester:
    """ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•çš„æ¨èç®—æ³•æ€§èƒ½æµ‹è¯•å™¨"""
    
    def __init__(self):
        self.profiler = PerformanceProfiler()
        self.test_users = []
        self.results = {
            'traditional': defaultdict(list),
            'optimized': defaultdict(list)
        }
    
    def create_test_scenarios(self, num_scenarios: int = 30) -> List[Dict]:
        """åˆ›å»ºæµ‹è¯•åœºæ™¯"""
        print(f"ğŸ”„ åˆ›å»º {num_scenarios} ä¸ªæµ‹è¯•åœºæ™¯...")
        
        spot_types = [
            "å†å²å»ºç­‘", "èµèŠ±èƒœåœ°", "èŒèŒåŠ¨ç‰©", "åŸå¸‚æ¼«æ­¥", "å¤œæ¸¸è§‚æ™¯",
            "é›å¨ƒå®è—åœ°", "å±•é¦†å±•è§ˆ", "åœ°æ ‡è§‚æ™¯", "ç™»é«˜çˆ¬å±±", "è¸é’å¿…å»",
            "è‡ªç„¶å±±æ°´", "æ¸¸ä¹åœº", "æ¼”å‡º"
        ]
        
        test_scenarios = []
        
        for i in range(num_scenarios):
            # éšæœºé€‰æ‹©1-5ä¸ªå–œå¥½ç±»å‹
            num_likes = random.randint(1, 5)
            likes = random.sample(spot_types, num_likes)
            
            scenario = {
                'scenario_id': f"scenario_{i}",
                'likes_type': likes,
                'description': f"åœºæ™¯{i}: å–œå¥½{len(likes)}ç§ç±»å‹ - {', '.join(likes)}"
            }
            test_scenarios.append(scenario)
        
        self.test_scenarios = test_scenarios
        print(f"âœ… æˆåŠŸåˆ›å»º {len(test_scenarios)} ä¸ªæµ‹è¯•åœºæ™¯")
        return test_scenarios
    
    def create_test_user(self, user_likes: List[str]) -> int:
        """åˆ›å»ºæµ‹è¯•ç”¨æˆ·å¹¶è¿”å›ç”¨æˆ·ID"""
        # ç”Ÿæˆå”¯ä¸€çš„æµ‹è¯•ç”¨æˆ·ID
        test_user_id = random.randint(100000, 999999)
        while any(u.id == test_user_id for u in userManager.users):
            test_user_id = random.randint(100000, 999999)
        
        test_user = User(
            id=test_user_id,
            name=f"test_user_{test_user_id}",
            password="test_password",
            likes_type=user_likes
        )
        # ä¸´æ—¶æ·»åŠ åˆ°ç”¨æˆ·ç®¡ç†å™¨ä¸­
        userManager.users.append(test_user)
        userManager.counts += 1
        return test_user_id
    
    def cleanup_test_user(self, user_id: int):
        """æ¸…ç†æµ‹è¯•ç”¨æˆ·"""
        userManager.users = [u for u in userManager.users if u.id != user_id]
        userManager.counts = len(userManager.users)
    
    def run_traditional_algorithm(self, user_likes: List[str], topK: int) -> Tuple[List, Dict]:
        """è¿è¡Œä¼ ç»Ÿç®—æ³•å¹¶æµ‹é‡æ€§èƒ½ - ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•"""
        self.profiler.start_profiling()
        test_user_id = None
        
        try:
            # åˆ›å»ºæµ‹è¯•ç”¨æˆ·å¹¶ç›´æ¥è°ƒç”¨ä¼ ç»Ÿæ–¹æ³•
            test_user_id = self.create_test_user(user_likes)
            result = userManager.getRecommendSpotsTraditional(test_user_id, topK)
            if result is None:
                result = []
            
        except Exception as e:
            print(f"âŒ ä¼ ç»Ÿç®—æ³•æ‰§è¡Œé”™è¯¯: {e}")
            result = []
        finally:
            # ç¡®ä¿æ¸…ç†æµ‹è¯•ç”¨æˆ·
            if test_user_id:
                self.cleanup_test_user(test_user_id)
        
        metrics = self.profiler.end_profiling()
        return result, metrics
    
    def run_optimized_algorithm(self, user_likes: List[str], topK: int) -> Tuple[List, Dict]:
        """è¿è¡Œä¼˜åŒ–ç®—æ³•å¹¶æµ‹é‡æ€§èƒ½ - ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•"""
        self.profiler.start_profiling()
        test_user_id = None
        
        try:
            # åˆ›å»ºæµ‹è¯•ç”¨æˆ·å¹¶ç›´æ¥è°ƒç”¨ä¼˜åŒ–æ–¹æ³•
            test_user_id = self.create_test_user(user_likes)
            result = userManager.getRecommendSpots(test_user_id, topK)
            if result is None:
                result = []
                
        except Exception as e:
            print(f"âŒ ä¼˜åŒ–ç®—æ³•æ‰§è¡Œé”™è¯¯: {e}")
            result = []
        finally:
            # ç¡®ä¿æ¸…ç†æµ‹è¯•ç”¨æˆ·
            if test_user_id:
                self.cleanup_test_user(test_user_id)
        
        metrics = self.profiler.end_profiling()
        return result, metrics
    
    def compare_results(self, traditional_result: List, optimized_result: List) -> Dict:
        """æ¯”è¾ƒä¸¤ç§ç®—æ³•çš„ç»“æœä¸€è‡´æ€§"""
        if not traditional_result and not optimized_result:
            return {
                'identical': True, 
                'similarity': 1.0, 
                'difference_count': 0,
                'traditional_count': 0,
                'optimized_count': 0
            }
        
        if not traditional_result or not optimized_result:
            return {
                'identical': False, 
                'similarity': 0.0, 
                'difference_count': max(len(traditional_result), len(optimized_result)),
                'traditional_count': len(traditional_result),
                'optimized_count': len(optimized_result)
            }
        
        # æå–IDé›†åˆè¿›è¡Œæ¯”è¾ƒ
        traditional_ids = {item['id'] for item in traditional_result}
        optimized_ids = {item['id'] for item in optimized_result}
        
        intersection = traditional_ids & optimized_ids
        union = traditional_ids | optimized_ids
        
        similarity = len(intersection) / len(union) if union else 1.0
        identical = traditional_ids == optimized_ids
        difference_count = len(union) - len(intersection)
        
        return {
            'identical': identical,
            'similarity': similarity,
            'difference_count': difference_count,
            'traditional_count': len(traditional_result),
            'optimized_count': len(optimized_result)
        }
    
    def run_comprehensive_test(self, topK_values: List[int] = None, iterations: int = 3) -> Dict:
        """è¿è¡Œå…¨é¢çš„æ€§èƒ½æµ‹è¯•"""
        if topK_values is None:
            topK_values = [5, 10, 20, 50]
        
        print("ğŸš€ å¼€å§‹å…¨é¢æ€§èƒ½æµ‹è¯•...")
        print(f"ğŸ“Š æµ‹è¯•å‚æ•°: topKå€¼={topK_values}, æµ‹è¯•åœºæ™¯æ•°={len(self.test_scenarios)}, æ¯ä¸ªåœºæ™¯é‡å¤={iterations}æ¬¡")
        print("=" * 80)
        
        overall_results = {
            'traditional': defaultdict(lambda: defaultdict(list)),
            'optimized': defaultdict(lambda: defaultdict(list)),
            'comparison': defaultdict(lambda: defaultdict(list))
        }
        
        for topK in topK_values:
            print(f"\nğŸ” æµ‹è¯• topK = {topK}")
            
            traditional_times = []
            optimized_times = []
            traditional_memories = []
            optimized_memories = []
            similarities = []
            
            for i, scenario in enumerate(self.test_scenarios):
                user_likes = scenario['likes_type']
                
                # å¤šæ¬¡æµ‹è¯•å–å¹³å‡å€¼
                scenario_traditional_times = []
                scenario_optimized_times = []
                scenario_traditional_memories = []
                scenario_optimized_memories = []
                scenario_similarities = []
                
                for iteration in range(iterations):
                    # æµ‹è¯•ä¼ ç»Ÿç®—æ³•
                    traditional_result, traditional_metrics = self.run_traditional_algorithm(user_likes, topK)
                    scenario_traditional_times.append(traditional_metrics['execution_time'])
                    scenario_traditional_memories.append(traditional_metrics['peak_memory_mb'])
                    
                    # æµ‹è¯•ä¼˜åŒ–ç®—æ³•
                    optimized_result, optimized_metrics = self.run_optimized_algorithm(user_likes, topK)
                    scenario_optimized_times.append(optimized_metrics['execution_time'])
                    scenario_optimized_memories.append(optimized_metrics['peak_memory_mb'])
                    
                    # æ¯”è¾ƒç»“æœ
                    comparison = self.compare_results(traditional_result, optimized_result)
                    scenario_similarities.append(comparison['similarity'])
                
                # è®°å½•å¹³å‡å€¼
                avg_traditional_time = np.mean(scenario_traditional_times)
                avg_optimized_time = np.mean(scenario_optimized_times)
                avg_traditional_memory = np.mean(scenario_traditional_memories)
                avg_optimized_memory = np.mean(scenario_optimized_memories)
                avg_similarity = np.mean(scenario_similarities)
                
                traditional_times.append(avg_traditional_time)
                optimized_times.append(avg_optimized_time)
                traditional_memories.append(avg_traditional_memory)
                optimized_memories.append(avg_optimized_memory)
                similarities.append(avg_similarity)
                
                if (i + 1) % 10 == 0:
                    print(f"  å·²å®Œæˆ {i + 1}/{len(self.test_scenarios)} ä¸ªåœºæ™¯")
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            avg_traditional = np.mean(traditional_times)
            avg_optimized = np.mean(optimized_times)
            speedup = avg_traditional / avg_optimized if avg_optimized > 0 else 0
            avg_similarity = np.mean(similarities)
            
            overall_results['traditional'][topK] = {
                'times': traditional_times,
                'avg_time': avg_traditional,
                'std_time': np.std(traditional_times),
                'memories': traditional_memories,
                'avg_memory': np.mean(traditional_memories),
                'std_memory': np.std(traditional_memories)
            }
            
            overall_results['optimized'][topK] = {
                'times': optimized_times,
                'avg_time': avg_optimized,
                'std_time': np.std(optimized_times),
                'memories': optimized_memories,
                'avg_memory': np.mean(optimized_memories),
                'std_memory': np.std(optimized_memories)
            }
            
            overall_results['comparison'][topK] = {
                'speedup': speedup,
                'similarities': similarities,
                'avg_similarity': avg_similarity,
                'std_similarity': np.std(similarities)
            }
            
            print(f"  âœ… topK={topK} æµ‹è¯•å®Œæˆ:")
            print(f"     ä¼ ç»Ÿç®—æ³•å¹³å‡æ—¶é—´: {avg_traditional*1000:.3f}ms")
            print(f"     ä¼˜åŒ–ç®—æ³•å¹³å‡æ—¶é—´: {avg_optimized*1000:.3f}ms")
            print(f"     æ€§èƒ½æå‡å€æ•°: {speedup:.2f}x")
            print(f"     ç»“æœç›¸ä¼¼åº¦: {avg_similarity:.3f}")
        
        self.results = overall_results
        return overall_results
    
    def visualize_results(self, save_path: str = "direct_method_performance_analysis.png"):
        """å¯è§†åŒ–æµ‹è¯•ç»“æœ"""
        if not self.results['traditional'] or not self.results['optimized']:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœå¯ä¾›å¯è§†åŒ–")
            return
        
        topK_values = list(self.results['traditional'].keys())
        
        # æå–æ•°æ®
        traditional_times = [self.results['traditional'][k]['avg_time'] * 1000 for k in topK_values]
        optimized_times = [self.results['optimized'][k]['avg_time'] * 1000 for k in topK_values]
        speedups = [self.results['comparison'][k]['speedup'] for k in topK_values]
        similarities = [self.results['comparison'][k]['avg_similarity'] for k in topK_values]
        
        # åˆ›å»ºå›¾è¡¨
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))
        
        # 1. æ‰§è¡Œæ—¶é—´å¯¹æ¯”
        x_pos = np.arange(len(topK_values))
        width = 0.35
        
        bars1 = ax1.bar(x_pos - width/2, traditional_times, width, 
                        label='ä¼ ç»Ÿç®—æ³•(Kè·¯å½’å¹¶)', color='lightcoral', alpha=0.8)
        bars2 = ax1.bar(x_pos + width/2, optimized_times, width,
                        label='ä¼˜åŒ–ç®—æ³•(IndexHeap)', color='lightblue', alpha=0.8)
        
        ax1.set_xlabel('TopKå€¼')
        ax1.set_ylabel('å¹³å‡æ‰§è¡Œæ—¶é—´ (æ¯«ç§’)')
        ax1.set_title('ç›´æ¥è°ƒç”¨æ–¹æ³•çš„æ€§èƒ½å¯¹æ¯”')
        ax1.set_xticks(x_pos)
        ax1.set_xticklabels(topK_values)
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar in bars1:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.2f}', ha='center', va='bottom', fontsize=10)
        for bar in bars2:
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.2f}', ha='center', va='bottom', fontsize=10)
        
        # 2. æ€§èƒ½æå‡å€æ•°
        bars3 = ax2.bar(topK_values, speedups, color='lightgreen', alpha=0.8)
        ax2.set_xlabel('TopKå€¼')
        ax2.set_ylabel('æ€§èƒ½æå‡å€æ•°')
        ax2.set_title('ä¼˜åŒ–ç®—æ³•ç›¸å¯¹ä¼ ç»Ÿç®—æ³•çš„æ€§èƒ½æå‡')
        ax2.grid(True, alpha=0.3)
        
        for bar in bars3:
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.2f}x', ha='center', va='bottom', fontsize=11, fontweight='bold')
        
        # 3. æ—¶é—´å¤æ‚åº¦è¶‹åŠ¿
        ax3.plot(topK_values, traditional_times, 'o-', label='ä¼ ç»Ÿç®—æ³•', 
                 color='red', linewidth=3, markersize=8)
        ax3.plot(topK_values, optimized_times, 's-', label='ä¼˜åŒ–ç®—æ³•', 
                 color='blue', linewidth=3, markersize=8)
        
        ax3.set_xlabel('TopKå€¼')
        ax3.set_ylabel('æ‰§è¡Œæ—¶é—´ (æ¯«ç§’)')
        ax3.set_title('æ‰§è¡Œæ—¶é—´éšTopKå€¼å˜åŒ–è¶‹åŠ¿')
        ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. ç»“æœç›¸ä¼¼åº¦
        bars4 = ax4.bar(topK_values, similarities, color='orange', alpha=0.8)
        ax4.set_xlabel('TopKå€¼')
        ax4.set_ylabel('ç»“æœç›¸ä¼¼åº¦')
        ax4.set_title('ä¸¤ç§ç®—æ³•ç»“æœç›¸ä¼¼åº¦å¯¹æ¯”')
        ax4.set_ylim([0, 1.1])
        ax4.grid(True, alpha=0.3)
        
        for bar in bars4:
            height = bar.get_height()
            ax4.text(bar.get_x() + bar.get_width()/2., height,
                    f'{height:.3f}', ha='center', va='bottom', fontsize=11)
        
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        print(f"ğŸ“Š æ€§èƒ½å¯¹æ¯”å›¾è¡¨å·²ä¿å­˜è‡³: {save_path}")
        plt.show()
    
    def generate_report(self, save_path: str = "direct_method_performance_report.md"):
        """ç”Ÿæˆè¯¦ç»†çš„æ€§èƒ½åˆ†ææŠ¥å‘Š"""
        if not self.results['traditional']:
            print("âŒ æ²¡æœ‰æµ‹è¯•ç»“æœå¯ä¾›ç”ŸæˆæŠ¥å‘Š")
            return
        
        topK_values = list(self.results['traditional'].keys())
        
        report_content = f"""# æ™¯ç‚¹æ¨èç®—æ³•æ€§èƒ½æµ‹è¯•æŠ¥å‘Š - ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•

## æµ‹è¯•æ¦‚è¿°

æœ¬æŠ¥å‘Šåˆ†æäº†ä¸ªæ€§åŒ–æ—…æ¸¸ç³»ç»Ÿä¸­æ™¯ç‚¹æ¨èç®—æ³•çš„å®é™…æ€§èƒ½è¡¨ç°ï¼Œé€šè¿‡ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•å¯¹æ¯”äº†ä¼ ç»ŸKè·¯å½’å¹¶ç®—æ³•ä¸åŸºäºIndexHeapçš„ä¼˜åŒ–ç®—æ³•ã€‚

### æµ‹è¯•ç¯å¢ƒ
- æµ‹è¯•åœºæ™¯æ•°é‡: {len(self.test_scenarios)}ä¸ªä¸åŒçš„ç”¨æˆ·å–œå¥½ç»„åˆ
- TopKæµ‹è¯•å€¼: {topK_values}
- æ¯ä¸ªåœºæ™¯é‡å¤æµ‹è¯•: 3æ¬¡
- æµ‹è¯•æ–¹æ³•: ç›´æ¥è°ƒç”¨UserManagerä¸­çš„åŸå§‹æ–¹æ³•

## æ€§èƒ½æµ‹è¯•ç»“æœ

### å¹³å‡æ‰§è¡Œæ—¶é—´å¯¹æ¯” (æ¯«ç§’)

| TopK | ä¼ ç»Ÿç®—æ³• | ä¼˜åŒ–ç®—æ³• | æ€§èƒ½æå‡ | æå‡ç‡ |
|------|----------|----------|----------|---------|
"""
        
        for topK in topK_values:
            traditional_time = self.results['traditional'][topK]['avg_time'] * 1000
            optimized_time = self.results['optimized'][topK]['avg_time'] * 1000
            speedup = self.results['comparison'][topK]['speedup']
            improvement = ((traditional_time - optimized_time) / traditional_time * 100) if traditional_time > 0 else 0
            
            report_content += f"| {topK} | {traditional_time:.3f} | {optimized_time:.3f} | {speedup:.2f}x | {improvement:.1f}% |\n"
        
        report_content += f"""

### å…³é”®å‘ç°

1. **æ•´ä½“æ€§èƒ½è¡¨ç°**: åœ¨æ‰€æœ‰TopKå€¼ä¸‹çš„å¹³å‡æ€§èƒ½å¯¹æ¯”
2. **ç®—æ³•ç¨³å®šæ€§**: é€šè¿‡å¤šæ¬¡é‡å¤æµ‹è¯•éªŒè¯ç»“æœçš„ä¸€è‡´æ€§
3. **ç»“æœå‡†ç¡®æ€§**: ä¸¤ç§ç®—æ³•ç»“æœçš„ç›¸ä¼¼åº¦åˆ†æ

### å†…å­˜ä½¿ç”¨åˆ†æ

"""
        
        for topK in topK_values:
            traditional_memory = self.results['traditional'][topK]['avg_memory']
            optimized_memory = self.results['optimized'][topK]['avg_memory']
            
            report_content += f"- **TopK={topK}**: ä¼ ç»Ÿç®—æ³• {traditional_memory:.2f}MB, ä¼˜åŒ–ç®—æ³• {optimized_memory:.2f}MB\\n"
        
        report_content += f"""

### ç»“æœç›¸ä¼¼åº¦åˆ†æ

"""
        
        for topK in topK_values:
            similarity = self.results['comparison'][topK]['avg_similarity']
            report_content += f"- **TopK={topK}**: å¹³å‡ç›¸ä¼¼åº¦ {similarity:.3f}\\n"
        
        report_content += f"""

## ç»“è®º

é€šè¿‡ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•çš„æµ‹è¯•ï¼Œæˆ‘ä»¬éªŒè¯äº†ä¸¤ç§æ¨èç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­çš„æ€§èƒ½è¡¨ç°ã€‚æµ‹è¯•ç»“æœæ˜¾ç¤ºäº†ä¼˜åŒ–ç®—æ³•åœ¨ä¸åŒåœºæ™¯ä¸‹çš„å®é™…æ•ˆæœã€‚

---

**æŠ¥å‘Šç”Ÿæˆæ—¶é—´**: {time.strftime("%Y-%m-%d %H:%M:%S")}  
**æµ‹è¯•ç‰ˆæœ¬**: ç›´æ¥æ–¹æ³•è°ƒç”¨æ€§èƒ½æµ‹è¯• v1.0
"""
        
        with open(save_path, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“ è¯¦ç»†æ€§èƒ½åˆ†ææŠ¥å‘Šå·²ä¿å­˜è‡³: {save_path}")

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 80)
    print("ğŸ”¬ æ™¯ç‚¹æ¨èç®—æ³•æ€§èƒ½æµ‹è¯• - ç›´æ¥è°ƒç”¨åŸå§‹æ–¹æ³•")
    print("=" * 80)
    
    try:
        # åˆ›å»ºæµ‹è¯•å™¨
        tester = DirectMethodPerformanceTester()
        
        # åˆ›å»ºæµ‹è¯•åœºæ™¯
        tester.create_test_scenarios(num_scenarios=20)  # ä½¿ç”¨è¾ƒå°‘çš„åœºæ™¯ä»¥åŠ å¿«æµ‹è¯•
        
        # è¿è¡Œæ€§èƒ½æµ‹è¯•
        print("\nğŸš€ å¼€å§‹æ€§èƒ½æµ‹è¯•...")
        results = tester.run_comprehensive_test(
            topK_values=[5, 10, 20, 50],
            iterations=3
        )
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        print("\nğŸ“Š ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨...")
        tester.visualize_results()
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        print("\nğŸ“ ç”Ÿæˆè¯¦ç»†æ€§èƒ½æŠ¥å‘Š...")
        tester.generate_report()
        
        print("\n" + "=" * 80)
        print("âœ… æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
        print("å·²ç”Ÿæˆ:")
        print("- æ€§èƒ½å¯¹æ¯”å›¾è¡¨: direct_method_performance_analysis.png")
        print("- è¯¦ç»†åˆ†ææŠ¥å‘Š: direct_method_performance_report.md")
        print("=" * 80)
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit_code = main()
    sys.exit(exit_code)
